{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TumorImagingBench: Getting Started\n",
    "\n",
    "Welcome to the TumorImagingBench tutorials! This notebook provides an overview of the framework and quick start instructions.\n",
    "\n",
    "## What is TumorImagingBench?\n",
    "\n",
    "TumorImagingBench is a framework for evaluating and comparing foundation model feature extractors for radiomics in medical imaging. It provides:\n",
    "\n",
    "- **Unified Model Interface**: All models inherit from `BaseModel` with consistent API\n",
    "- **Dynamic Model Registration**: Add models at runtime without modifying core code\n",
    "- **Flexible Feature Extraction**: Dataset-specific extractors with configurable paths\n",
    "- **GPU-Accelerated Inference**: CUDA support for efficient feature extraction\n",
    "- **Extensible Architecture**: Easy to add new models and datasets\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "cd /path/to/TumorImagingBench\n",
    "uv sync\n",
    "```\n",
    "\n",
    "## Quick Start: Check Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/Repositories/TumorImagingBench/.venv/lib/python3.11/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:261: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/suraj/Repositories/TumorImagingBench/.venv/lib/python3.11/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Registered extractor: CTClipVitExtractor\n",
      "✓ Registered extractor: CTFMExtractor\n",
      "✓ Registered extractor: FMCIBExtractor\n",
      "Warning: MedImageInsightExtractor not available due to missing dependencies: No module named 'MedImageInsight'\n",
      "✓ Registered extractor: MerlinExtractor\n",
      "✓ Registered extractor: ModelsGenExtractor\n",
      "✓ Registered extractor: PASTAExtractor\n",
      "✓ Registered extractor: SUPREMExtractor\n",
      "✓ Registered extractor: VISTA3DExtractor\n",
      "✓ Registered extractor: VocoExtractor\n",
      "✓ Registered extractor: DummyResNetExtractor\n",
      "Available models (10):\n",
      "  - CTClipVitExtractor\n",
      "  - CTFMExtractor\n",
      "  - FMCIBExtractor\n",
      "  - MerlinExtractor\n",
      "  - ModelsGenExtractor\n",
      "  - PASTAExtractor\n",
      "  - SUPREMExtractor\n",
      "  - VISTA3DExtractor\n",
      "  - VocoExtractor\n",
      "  - DummyResNetExtractor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/suraj/Repositories/TumorImagingBench/src')\n",
    "\n",
    "from tumorimagingbench.models import get_available_extractors, get_extractor\n",
    "\n",
    "# List all available models\n",
    "available = get_available_extractors()\n",
    "print(f\"Available models ({len(available)}):\")\n",
    "for name in available:\n",
    "    \n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Load and Test a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "required package for reader ITKReader is not installed, or the version doesn't match requirement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model instantiated: DummyResNetExtractor\n",
      "✓ Weights loaded\n",
      "✓ Model moved to cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the DummyResNetExtractor (a simple example model)\n",
    "DummyResNet = get_extractor('DummyResNetExtractor')\n",
    "\n",
    "# Instantiate the model\n",
    "model = DummyResNet()\n",
    "print(f\"✓ Model instantiated: {model.__class__.__name__}\")\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load()\n",
    "print(\"✓ Weights loaded\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "print(f\"✓ Model moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 1, 48, 48, 48])\n",
      "Output shape: torch.Size([2, 512])\n",
      "Output type: <class 'torch.Tensor'>\n",
      "Output dtype: torch.float32\n",
      "\n",
      "Feature statistics:\n",
      "  Mean: 0.825305\n",
      "  Std: 0.122632\n",
      "  Min: 0.457164\n",
      "  Max: 1.180106\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create dummy input (batch_size=2, channels=1, height=48, width=48, depth=48)\n",
    "dummy_input = torch.randn(2, 1, 48, 48, 48, device=device)\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# Extract features\n",
    "features = model.forward(dummy_input)\n",
    "print(f\"Output shape: {features.shape}\")\n",
    "print(f\"Output type: {type(features)}\")\n",
    "print(f\"Output dtype: {features.dtype}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(f\"  Mean: {features.mean():.6f}\")\n",
    "print(f\"  Std: {features.std():.6f}\")\n",
    "print(f\"  Min: {features.min():.6f}\")\n",
    "print(f\"  Max: {features.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework Architecture\n",
    "\n",
    "### Component Overview\n",
    "\n",
    "```\n",
    "TumorImagingBench/\n",
    "├── src/tumorimagingbench/\n",
    "│   ├── models/                 # Foundation model extractors\n",
    "│   │   ├── base.py             # BaseModel abstract class\n",
    "│   │   ├── __init__.py         # Model registry\n",
    "│   │   ├── dummy_resnet.py     # Example model\n",
    "│   │   └── [other models]      # 10+ foundation models\n",
    "│   │\n",
    "│   └── evaluation/             # Feature extraction pipeline\n",
    "│       ├── base_feature_extractor.py  # Core extraction logic\n",
    "│       ├── dummy_dataset_feature_extractor.py  # Example dataset\n",
    "│       └── [dataset extractors]       # One per dataset\n",
    "│\n",
    "└── tutorials/                  # Documentation and examples\n",
    "    ├── 00_getting_started.ipynb\n",
    "    ├── 01_model_integration.ipynb\n",
    "    ├── 02_feature_extractor_guide.ipynb\n",
    "    └── 03_api_reference.ipynb\n",
    "```\n",
    "\n",
    "### Model Registry System\n",
    "\n",
    "All models are registered in `AVAILABLE_EXTRACTORS` dictionary:\n",
    "\n",
    "```python\n",
    "AVAILABLE_EXTRACTORS = {\n",
    "    'DummyResNetExtractor': DummyResNetExtractor,\n",
    "    'CTClipVitExtractor': CTClipVitExtractor,\n",
    "    'FMCIBExtractor': FMCIBExtractor,\n",
    "    # ... more models\n",
    "}\n",
    "```\n",
    "\n",
    "### Feature Extraction Pipeline\n",
    "\n",
    "1. **Dataset Loading**: `get_split_data()` returns pandas DataFrame\n",
    "2. **Row Processing**: `preprocess_row()` validates each sample\n",
    "3. **Model Preprocessing**: `model.preprocess()` loads NIFTI and extracts patch\n",
    "4. **Feature Extraction**: `model.forward()` extracts features on GPU\n",
    "5. **Parallel Processing**: Multiprocessing across models\n",
    "6. **Feature Saving**: Results saved as pickle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### BaseModel Interface\n",
    "\n",
    "All models must implement three abstract methods:\n",
    "\n",
    "1. **`load(weights_path=None)`** - Load pre-trained weights\n",
    "   - Called after `__init__()`\n",
    "   - Should set model to eval mode\n",
    "   - Optional parameter for custom weights\n",
    "\n",
    "2. **`preprocess(x)`** - Convert input dict to tensor\n",
    "   - Input: `{'image_path': str, 'coordX': float, 'coordY': float, 'coordZ': float}`\n",
    "   - Output: `torch.Tensor` of shape `(1, H, W, D)` or `(C, H, W, D)`\n",
    "   - Handles: NIFTI loading, orientation, resampling, cropping, normalization\n",
    "\n",
    "3. **`forward(x)`** - Extract features\n",
    "   - Input: `torch.Tensor` of shape `(batch_size, channels, height, width, depth)`\n",
    "   - Output: `numpy.ndarray` of shape `(batch_size, feature_dim)`\n",
    "   - Must be on CPU\n",
    "   - No gradients computed\n",
    "\n",
    "### Input Data Format\n",
    "\n",
    "Models expect physical (mm) coordinates for the region of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input format:\n",
      "  image_path: /path/to/ct_scan.nii.gz\n",
      "  coordX: 100.5\n",
      "  coordY: 150.3\n",
      "  coordZ: 200.1\n",
      "  label: 0\n"
     ]
    }
   ],
   "source": [
    "# Example input format (what get_split_data() should return)\n",
    "example_row = {\n",
    "    'image_path': '/path/to/ct_scan.nii.gz',  # NIFTI file\n",
    "    'coordX': 100.5,                           # X centroid in mm\n",
    "    'coordY': 150.3,                           # Y centroid in mm\n",
    "    'coordZ': 200.1,                           # Z centroid in mm\n",
    "    'label': 0,                                # Optional: label for downstream tasks\n",
    "}\n",
    "\n",
    "print(\"Example input format:\")\n",
    "for key, value in example_row.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Tasks\n",
    "\n",
    "### Task 1: List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['CTFMExtractor', 'FMCIBExtractor', 'MerlinExtractor', 'ModelsGenExtractor', 'PASTAExtractor', 'SUPREMExtractor', 'VISTA3DExtractor', 'VocoExtractor', 'DummyResNetExtractor']\n"
     ]
    }
   ],
   "source": [
    "from tumorimagingbench.models import get_available_extractors\n",
    "\n",
    "models = get_available_extractors()\n",
    "print(f\"Available models: {models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Extract Features for Specific Models and for preloaded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using command line\n",
    "# python nsclc_radiomics_feature_extractor.py \\\n",
    "#   --output features/nsclc.pkl \\\n",
    "#   --models DummyResNetExtractor CTClipVitExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Register a Custom Model at Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Registered extractor: MyCustomModel\n",
      "Available models: ['CTFMExtractor', 'FMCIBExtractor', 'MerlinExtractor', 'ModelsGenExtractor', 'PASTAExtractor', 'SUPREMExtractor', 'VISTA3DExtractor', 'VocoExtractor', 'DummyResNetExtractor', 'MyCustomModel']\n"
     ]
    }
   ],
   "source": [
    "from tumorimagingbench.models import register_extractor, BaseModel\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your custom model\n",
    "class MyCustomModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(48*48*48, 512)\n",
    "    \n",
    "    def load(self, weights_path=None):\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        # Placeholder - in reality would use get_transforms()\n",
    "        return torch.randn(1, 1, 48, 48, 48)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x.cpu().numpy()\n",
    "\n",
    "# Register it\n",
    "register_extractor('MyCustomModel', MyCustomModel)\n",
    "\n",
    "# Now it's available\n",
    "print(f\"Available models: {get_available_extractors()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **To integrate a new model**: Go to [01_model_integration.ipynb](./01_model_integration.ipynb)\n",
    "2. **To add a new dataset**: Go to [02_feature_extractor_guide.ipynb](./02_feature_extractor_guide.ipynb)\n",
    "3. **For API details**: Check [03_api_reference.ipynb](./03_api_reference.ipynb)\n",
    "\n",
    "## Documentation Structure\n",
    "\n",
    "- **00_getting_started.ipynb** (this file) - Overview and quick start\n",
    "- **01_model_integration.ipynb** - How to add a new foundation model\n",
    "- **02_feature_extractor_guide.ipynb** - How to add a new dataset\n",
    "- **03_api_reference.ipynb** - Complete API documentation\n",
    "\n",
    "## Key Directories\n",
    "\n",
    "- **Models**: `src/tumorimagingbench/models/`\n",
    "- **Feature Extractors**: `src/tumorimagingbench/evaluation/`\n",
    "- **Tutorials**: `tutorials/` (you are here)\n",
    "- **Examples**: `tutorials/examples/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
